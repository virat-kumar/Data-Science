{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.5.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.1/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 0.3/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.6/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.9/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 0.9/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.1/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.3/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.10.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (4.65.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "     --------- ----------------------------- 71.7/298.0 kB 3.8 MB/s eta 0:00:01\n",
      "     ------------ -------------------------- 92.2/298.0 kB 1.7 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 143.4/298.0 kB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 174.1/298.0 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 266.2/298.0 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 266.2/298.0 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 266.2/298.0 kB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ 298.0/298.0 kB 877.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 0.0/267.7 kB ? eta -:--:--\n",
      "     --------------- ---------------------- 112.6/267.7 kB 3.3 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 143.4/267.7 kB 1.7 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 194.6/267.7 kB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 256.0/267.7 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 267.7/267.7 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vk001\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1 regex-2022.10.31\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# %pip install spacy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [\n",
    "    \"Apple to bring a hong Kong factory for $8 million\",\n",
    "    \"Autonomous cars shift insurance liability towards manufactures\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  Apple to bring a hong Kong factory for $8 million\n",
      "\t Apple|\t to|\t bring|\t a|\t hong|\t Kong|\t factory|\t for|\t $|\t 8|\t million|\t\tEntities\n",
      "\t<Apple, ORG> Companies, agencies, institutions, etc.\n",
      "\t<hong Kong, GPE> Countries, cities, states\n",
      "\t<$8 million, MONEY> Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(strings[0])\n",
    "print(\"sentence: \" , strings[0])\n",
    "\n",
    "for token in doc:\n",
    "    print(\"\\t\", token.text, end= \"|\")\n",
    "print(\"\\t\\tEntities\")\n",
    "for entity in doc.ents:\n",
    "    print(f\"\\t<{entity}, {entity.label_}>\", spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Apple, ORG> Companies, agencies, institutions, etc.\n",
      "<hong Kong, GPE> Countries, cities, states\n",
      "<$8 million, MONEY> Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(f\"<{entity}, {entity.label_}>\", spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars shift insurance liability towards manufactures\n",
      "Autonomous cars|insurance liability|manufactures|"
     ]
    }
   ],
   "source": [
    "doc = nlp(strings[1])\n",
    "print(doc)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk, end = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b8dbf312eba64b0ab8a7d1d3696aaefc-0\" class=\"displacy\" width=\"680\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">cars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">shift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">insurance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">liability</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">towards</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">manufactures</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,47.0 135.0,47.0 135.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-1\" stroke-width=\"2px\" d=\"M160,92.0 C160,47.0 225.0,47.0 225.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,94.0 L152,82.0 168,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-2\" stroke-width=\"2px\" d=\"M340,92.0 C340,47.0 405.0,47.0 405.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,94.0 L332,82.0 348,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-3\" stroke-width=\"2px\" d=\"M250,92.0 C250,2.0 410.0,2.0 410.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M410.0,94.0 L418.0,82.0 402.0,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-4\" stroke-width=\"2px\" d=\"M430,92.0 C430,47.0 495.0,47.0 495.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,94.0 L503.0,82.0 487.0,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-5\" stroke-width=\"2px\" d=\"M520,92.0 C520,47.0 585.0,47.0 585.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8dbf312eba64b0ab8a7d1d3696aaefc-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,94.0 L593.0,82.0 577.0,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\",jupyter = True, options={\"distance\":90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Over the last quater apple solud nearly 40 thousands ipods for a profit of $60 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quater\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " apple solud \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 40 thousands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " ipods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $60 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'ent', jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "s_stemmer = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"run\", \n",
    "    \"runner\",\n",
    "    \"ran\",\n",
    "    \"runs\",\n",
    "    \"easily\",\n",
    "    \"fairly\",\n",
    "    \"fairness\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run||run\n",
      "runner-->runner||runner\n",
      "ran-->ran||ran\n",
      "runs-->run||run\n",
      "easily-->easili||easili\n",
      "fairly-->fairli||fair\n",
      "fairness-->fair||fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"-->\" + p_stemmer.stem(word)+ \"||\" + s_stemmer.stem(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I am a runner running in a race because I love to run since I ran today\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\tPRON\t4690420944186131903\tI\n",
      "am\tAUX\t10382539506755952630\tbe\n",
      "a\tDET\t11901859001352538922\ta\n",
      "runner\tNOUN\t12640964157389618806\trunner\n",
      "running\tVERB\t12767647472892411841\trun\n",
      "in\tADP\t3002984154512732771\tin\n",
      "a\tDET\t11901859001352538922\ta\n",
      "race\tNOUN\t8048469955494714898\trace\n",
      "because\tSCONJ\t16950148841647037698\tbecause\n",
      "I\tPRON\t4690420944186131903\tI\n",
      "love\tVERB\t3702023516439754181\tlove\n",
      "to\tPART\t3791531372978436496\tto\n",
      "run\tVERB\t12767647472892411841\trun\n",
      "since\tSCONJ\t10066841407251338481\tsince\n",
      "I\tPRON\t4690420944186131903\tI\n",
      "ran\tVERB\t12767647472892411841\trun\n",
      "today\tNOUN\t11042482332948150395\ttoday\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text}\\t{token.pos_}\\t{token.lemma}\\t{token.lemma_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase matching and pattern matching  \n",
    "[Examples](https://spacy.pythonhumanities.com/02_02_matcher.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Science\n",
      "Learner\n",
      "contact@datasciencelearner.com\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [\n",
    "    [{\"LIKE_EMAIL\": True}], \n",
    "    [{\"POS\": \"PROPN\"}]\n",
    "    ]\n",
    "matcher.add(\"My_Pattern\",pattern)\n",
    "\n",
    "text = \"You can contact Data Science Learner through email address contact@datasciencelearner.com\"\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id,start,end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vk001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vk001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vk001\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download the NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox, jumps over the lazy dog!\n",
      "the quick brown fox, jumps over the lazy dog!\n",
      "the quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the text to be normalized\n",
    "text = \"The quick brown fox, jumps over the lazy dog!\"\n",
    "print(text)\n",
    "# Convert all characters to lowercase\n",
    "text = text.lower()\n",
    "print(text)\n",
    "# Remove any punctuation marks\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed tokens \n",
      " ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform stemming\n",
    "stemmer = PorterStemmer()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(\"stemmed tokens \\n\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in lemmatized_tokens if not token in stop_words]\n",
    "\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
