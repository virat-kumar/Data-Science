{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will see the use of fuzzy string matching. \n",
    "Sometimes we see that we are trying to refer to the same thing in different ways because it is written differently or it is misspelled or we have typos. This problem often occurs in databases.So, lets see how we can fuzzy match strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we usually compare strings in python like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Microsoft Corp.\"\n",
    "str2 = \"Microsoft Corp.\"\n",
    "Result = str1 == str2\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if any of the string changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Microsoft Corp.\"\n",
    "str2 = \"microsoft Corp.\"\n",
    "Result = str1 == str2\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got False even if both the strings mena the same company. So, if we convert both strings to lower case, we will solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Microsoft Corp.\"\n",
    "str2 = \"microsoft Corp.\"\n",
    "Result = str1.lower() == str2.lower()\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem comes when characters are missing from the strings. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Microsoft Corp.\"\n",
    "str2 = \"microsoft Corp.\"\n",
    "Result = str1.lower() == str2.lower()\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These type of problems often occur in databases and we therefore need strong tools to compare strings. One such tools is 'Levenshtein distance'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance \n",
    "It is a metric used to measure distance between two strings meaning how apart are two sequence of words. It measures the minimum number of edits that should be done to change a one-word sequence to the other.The edits can be insertion, deletion or substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def levenshtein_ratio_and_distance(s, t, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of s and the\n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "        return Ratio\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert string a to string b\n",
    "        return \"The strings are {} edits away\".format(distance[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strings are 2 edits away\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Snap Inc.\"\n",
    "str2 = \"snap Inc\"\n",
    "Distance = levenshtein_ratio_and_distance(str1,str2)\n",
    "print(Distance)\n",
    "Ratio = levenshtein_ratio_and_distance(str1,str2,ratio_calc = True)\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do very simple string preprocessing before calculating distance we will see that the output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strings are 1 edits away\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Snap Inc.\"\n",
    "str2 = \"snap Inc\"\n",
    "Distance = levenshtein_ratio_and_distance(str1.lower(),str2.lower())\n",
    "print(Distance)\n",
    "Ratio = levenshtein_ratio_and_distance(str1,str2,ratio_calc = True)\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, the distance has been reduced by 1 simply because the strings have been turned to lower case before comparing and hence, the similarity ratio reaches almost 95%. This emphasizes the relevance of string preprocessing before performing calculations. If we were, say, choosing if a string is similar to another one based on a similarity threshold of 90%, then \"Apple Inc.\" and \"apple Inc\" without preprocessing would be marked as not similar.\n",
    "Lets try to use the levenshtein package in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "str1 = \"Apple Inc.\"\n",
    "str2 = \"apple Inc\"\n",
    "Distance = lev.distance(str1.lower(),str2.lower()),\n",
    "print(Distance)\n",
    "Ratio = lev.ratio(str1.lower(),str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets explore FuzzyWuzzy package\n",
    "This package in python is very useful when the levenshtein distance ratio of similarity between two strings falls short. Our examples were very simple where we had difference in cases (lower/upper) and periods. But what happens when something is spelled out of order?\n",
    "What happens when has a lot of variation in spelling but it still refers to the same thing?\n",
    "FuzzyWuzzy package is to the rescue because it has functions that allow our fuzzy matching scripts to handle these sorts of cases.\n",
    "\n",
    "FuzzyWuzzy has, just like the Levenshtein package, a ratio function that computes the standard Levenshtein distance similarity ratio between two sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "str1 = \"Apple Inc.\"\n",
    "str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(str1.lower(),str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more like we saw in the above examples. FuzzyWuzzy has more powerful functions that allow us to deal with more complex situations such as substring matching. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 48\n",
      "Partial ratio: 100\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Seattle Park Riders\"\n",
    "str2 = \"Riders\"\n",
    "Ratio = fuzz.ratio(str1.lower(),str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(str1.lower(),str2.lower())\n",
    "print(\"Ratio:\",Ratio)\n",
    "print(\"Partial ratio:\",Partial_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fuzz.partial_ratio() function, we are able to detect that both strings are referring to the Riders. Thus, we see 100% similarity. This works using an \"optimal partial\" logic. So, what happens is if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is not foolproof. What happens when the strings comparison is the same, but they are in a different order? Fuzzywuzzy is useful here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 70\n",
      "Partial_Ratio 70\n",
      "Partial_Ratio 100\n"
     ]
    }
   ],
   "source": [
    "str1 = \"India vs New Zealand World Cup\"\n",
    "str2 = \"New Zealand World Cup vs India\"\n",
    "Ratio = fuzz.ratio(str1.lower(),str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(str1.lower(),str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(str1,str2)\n",
    "print(\"Ratio\", Ratio)\n",
    "print(\"Partial_Ratio\", Partial_Ratio)\n",
    "print(\"Partial_Ratio\", Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows us to judge if the strings are actually the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the question is what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in. See below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 62\n",
      "Partial_Ratio 84\n",
      "Token_Sort_Ratio 62\n",
      "Token_Set_Ratio 100\n"
     ]
    }
   ],
   "source": [
    "str1 = \"The supreme court case of Facebook vs The United States\"\n",
    "str2 = \"Facebook vs United States\"\n",
    "Ratio = fuzz.ratio(str1.lower(),str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(str1.lower(),str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(str1,str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(str1,str2)\n",
    "print(\"Ratio\", Ratio)\n",
    "print(\"Partial_Ratio\", Partial_Ratio)\n",
    "print(\"Token_Sort_Ratio\", Token_Sort_Ratio)\n",
    "print(\"Token_Set_Ratio\", Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here in the above scenario, instead of just tokenizing the strings, sorting and then joining the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection\n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens\n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the fuzzywuzzy package has a module called process that allows you to calculate the string with the highest similarity out of a vector of strings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple Inc.', 100), ('Apple incorporated', 90), ('Apple park', 67), ('iphone', 30)]\n",
      "('apple Inc.', 100)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "str2Match = \"Apple inc\"\n",
    "strOptions = [\"apple Inc.\",\"Apple park\",\"Apple incorporated\",\"iphone\"]\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "print(Ratios)\n",
    "# You can also select the string with the highest matching percentage\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "print(highest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
